{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train KNN on character Recognition Dataset\n",
    "from sklearn import datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "U\n",
      "V\n",
      "W\n",
      "X\n",
      "Y\n",
      "Z\n",
      "(35502, 7500)\n"
     ]
    }
   ],
   "source": [
    "#Import all data and convert it into binary form.\n",
    "#Flatten data and append to one large array. Each row is an image data points\n",
    "#This is the training dataset to fit the KNN algorithm\n",
    "character_directory = r\"C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Character Fit Dataset\\CNN letter Dataset\"\n",
    "image_data = []\n",
    "count = 0\n",
    "for filename in os.listdir(character_directory):\n",
    "    print(filename)\n",
    "    files = os.path.join(character_directory,filename)\n",
    "    for character_file in os.listdir(files):\n",
    "        os.chdir(files)\n",
    "        image = cv2.imread(character_file)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _,thresh = cv2.threshold(gray,85,255, cv2.THRESH_BINARY)\n",
    "        flatten_image = thresh.flatten()\n",
    "        if count == 0:\n",
    "            image_data = flatten_image\n",
    "            count = count+1\n",
    "        if count == 1:\n",
    "            image_data = np.vstack([image_data, flatten_image])\n",
    "print(np.shape(image_data))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 75)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35500, 7500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_data = image_data[:-2]\n",
    "print(np.shape(image_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35502,)\n"
     ]
    }
   ],
   "source": [
    "# Create array of labels that match the training dataset. The dataset was unlabeled pre processing\n",
    "labels = np.array([1]*1030+[2]*1032+[3]*1030+[4]*1030+[5]*1030+[6]*1030+[7]*1030+[8]*1030+[9]*1030+[10]*1030+\n",
    "[11]*1010+[12]*1030+[13]*1020+[14]*1010+[15]*1010+[16]*1020+[17]*1020+[18]*1020+[19]*1010+[20]*1030+[21]*1010+[22]*1010+\n",
    "[23]*1020+[24]*1020+[25]*1010+[26]*1010+[27]*1020+[28]*1020+[29]*1020+[30]*1010+[31]*1030+[32]*1010+[33]*1010+[34]*1010+[35]*810)\n",
    "print(np.shape(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a KNN model over the image data and labels\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "knn.fit(image_data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_01334X2\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_1MA625\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_215557W\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "ROI_7.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_2A00315\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_2A01D46\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_2A0BAN8\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_4685BH5\n",
      "ROI_1.png\n",
      "ROI_10.png\n",
      "ROI_2.png\n",
      "ROI_4.png\n",
      "ROI_6.png\n",
      "ROI_8.png\n",
      "ROI_9.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_4WES842\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_5269QD\n",
      "ROI_0.png\n",
      "ROI_2.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_66880\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_73309E2\n",
      "ROI_0.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "ROI_7.png\n",
      "ROI_8.png\n",
      "ROI_9.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_7373XT\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_762589B\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_862FAL\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_936TFJ\n",
      "ROI_0.png\n",
      "ROI_2.png\n",
      "ROI_4.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_APV9135\n",
      "ROI_0.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_CN73122\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_PMF2472\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_QJU533\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_SCARPY\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_TDL6006\n",
      "ROI_10.png\n",
      "ROI_11.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "ROI_8.png\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_TUL605\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_VHE706\n",
      "C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_VUI159\n",
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "ROI_7.png\n",
      "ROI_8.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13384\\4052154849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mpredict_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten_image\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aksha\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Obtain the individual character images\n",
    "# Loop over the split character folders and extract images from each individual folder\n",
    "# Binarize and flatten the dataset to match the training data KNN was fit too.\n",
    "character_directory = r\"C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\"\n",
    "predict_data = []\n",
    "count = 0\n",
    "for filename in os.listdir(character_directory):\n",
    "    files = os.path.join(character_directory,filename)\n",
    "    print(files)\n",
    "    for character_file in os.listdir(files):\n",
    "        os.chdir(files)\n",
    "        image = cv2.imread(character_file)\n",
    "        print(character_file)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        flatten_image = gray.flatten()\n",
    "        if count == 0:\n",
    "            predict_data = flatten_image\n",
    "            count = count+1\n",
    "        if count == 1:\n",
    "            predict_data = np.vstack([image_data, flatten_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7500)\n",
      "['I']\n"
     ]
    }
   ],
   "source": [
    "# Testing out KNN model on one individual license plate for research purposes\n",
    "c_dir = r\"C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_01334X2\"\n",
    "os.chdir(c_dir)\n",
    "img_rd = cv2.imread('ROI_5.png')\n",
    "gray = cv2.cvtColor(img_rd, cv2.COLOR_BGR2GRAY)\n",
    "img_rd = gray.flatten()\n",
    "img_rd = np.expand_dims(img_rd,axis=1)\n",
    "print(np.shape(img_rd.T))\n",
    "pred = knn.predict(img_rd.T)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35501, 7500)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(predict_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI_0.png\n",
      "ROI_1.png\n",
      "ROI_2.png\n",
      "ROI_3.png\n",
      "ROI_4.png\n",
      "ROI_5.png\n",
      "ROI_6.png\n",
      "(7, 7500)\n"
     ]
    }
   ],
   "source": [
    "# Loop through the flattened data from the repective folders and append to array to be tested\n",
    "import string\n",
    "alphabet = list(string.ascii_uppercase)\n",
    "characters = [0,1,2,3,4,5,6,7,8,9]+alphabet+[\"a\",\"b\",\"d\",\"e\",\"f\",\"g\",\"h\",\"n\",\"q\",\"r\",\"t\"]\n",
    "c_dir = r\"C:\\Users\\aksha\\OneDrive\\Desktop\\Desktop\\Fall 2022\\Introduction to ML and AI\\Project\\Split_Characters\\split_01334X2\"\n",
    "test_d = []\n",
    "count = 0\n",
    "for character_file in os.listdir(c_dir):\n",
    "    os.chdir(c_dir)\n",
    "    print(character_file)\n",
    "    image = cv2.imread(character_file)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_rd = gray.flatten()\n",
    "    #print(img_rd.T)\n",
    "    if count == 0:\n",
    "        test_d = img_rd.T\n",
    "        count = count+1\n",
    "    else:\n",
    "        test_d = np.vstack([test_d, img_rd.T])\n",
    "print(np.shape(test_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I\n",
      "0\n",
      "G\n",
      "I\n",
      "I\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Loop through each row and predict the character.\n",
    "pred_own = knn.predict(test_d)\n",
    "for i in range(len(pred_own)):\n",
    "    c = int(pred_own[i])\n",
    "    pred_char = characters[c-1]\n",
    "    print(pred_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343b9d0de72b544a3a66ffbeb0c5a344da563f6919711ad31afce86eabca835e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
