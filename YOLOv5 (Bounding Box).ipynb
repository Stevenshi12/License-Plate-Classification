{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aRpYOwIbRu1"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nPuGcIjdTAq",
        "outputId": "232eb075-403f-46bb-ed46-afb8cfa7f420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone yolv5 repo\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0i11UI3enNM",
        "outputId": "9cd985b7-51ec-456c-ca18-9532b44418e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14437, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 14437 (delta 57), reused 67 (delta 37), pack-reused 14342\u001b[K\n",
            "Receiving objects: 100% (14437/14437), 13.42 MiB | 11.64 MiB/s, done.\n",
            "Resolving deltas: 100% (9958/9958), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change dir to yolov5\n",
        "cd yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgcRujsjf0Y0",
        "outputId": "319e6a5b-3c52-4346-8f77-afaa50ceaac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fsd3DDIf16H",
        "outputId": "90150b23-69b6-46ec-8d38-b2414c933e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (5.4.8)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.1.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.50.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (5.1.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 41)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 41)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 41)) (0.7.0)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download yolov5s pretrained weights\n",
        "!wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxAK6TkCf5aA",
        "outputId": "1338d7be-ff5b-4bc0-b3af-b6c9f4033b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-03 16:39:20--  https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221103T163920Z&X-Amz-Expires=300&X-Amz-Signature=7ad470db20c8b2e98634856912371e04437331bb37158a4c456fe07755ac0d86&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-03 16:39:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221103T163920Z&X-Amz-Expires=300&X-Amz-Signature=7ad470db20c8b2e98634856912371e04437331bb37158a4c456fe07755ac0d86&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14698491 (14M) [application/octet-stream]\n",
            "Saving to: ‘yolov5s.pt’\n",
            "\n",
            "yolov5s.pt          100%[===================>]  14.02M  14.5MB/s    in 1.0s    \n",
            "\n",
            "2022-11-03 16:39:22 (14.5 MB/s) - ‘yolov5s.pt’ saved [14698491/14698491]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train on weights (we trained the first time using yolov5s weights; after, we retrained using weights from previous trials)\n",
        "!python train.py --img 1920 --batch 8 --epochs 20 --data '/content/drive/MyDrive/ML-AI Project/YOLO_Bounding_Box/dataset.yaml' --weights /content/yolov5/runs/train/exp3/weights/last.pt --nosave --cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKszwygQgOwy",
        "outputId": "fa28aa3f-ec23-4595-960d-762c72ad1fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/runs/train/exp3/weights/last.pt, cfg=, data=/content/drive/MyDrive/ML-AI Project/YOLO_Bounding_Box/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=8, imgsz=1920, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 1 commit. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v6.2-224-g82a5585 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from /content/yolov5/runs/train/exp3/weights/last.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/ML-AI Project/YOLO_Bounding_Box/data/train/labels.cache' images and labels... 43 found, 0 missing, 0 empty, 0 corrupt: 100% 43/43 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB ram): 100% 43/43 [00:01<00:00, 30.85it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/ML-AI Project/YOLO_Bounding_Box/data/val/labels.cache' images and labels... 66 found, 4 missing, 0 empty, 0 corrupt: 100% 70/70 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.4GB ram): 100% 70/70 [00:04<00:00, 15.64it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.76 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp4/labels.jpg... \n",
            "Image sizes 1920 train, 1920 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19      13.3G    0.04169    0.01722          0         12       1920: 100% 6/6 [00:07<00:00,  1.27s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.49it/s]\n",
            "                   all         70        108      0.784      0.605       0.64      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19      13.3G    0.03754    0.01501          0          4       1920: 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.42it/s]\n",
            "                   all         70        108      0.763      0.597      0.613      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19      13.3G    0.04037    0.01831          0          8       1920: 100% 6/6 [00:04<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.53it/s]\n",
            "                   all         70        108      0.762      0.602      0.613      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19      13.3G    0.03875    0.01545          0          9       1920: 100% 6/6 [00:04<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.43it/s]\n",
            "                   all         70        108      0.625       0.62      0.566      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19      13.3G    0.04453    0.01864          0         11       1920: 100% 6/6 [00:04<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.52it/s]\n",
            "                   all         70        108      0.673      0.593      0.573      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19      13.3G    0.04896    0.01532          0          4       1920: 100% 6/6 [00:04<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.60it/s]\n",
            "                   all         70        108      0.435      0.563      0.367      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19      13.3G    0.04451    0.01551          0          9       1920: 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.54it/s]\n",
            "                   all         70        108      0.496      0.612       0.47      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19      13.3G     0.0551    0.01765          0          8       1920: 100% 6/6 [00:04<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.49it/s]\n",
            "                   all         70        108      0.455      0.509      0.381      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19      13.3G    0.04946    0.01562          0          8       1920: 100% 6/6 [00:04<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.52it/s]\n",
            "                   all         70        108      0.784      0.605      0.638      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19      13.3G     0.0435    0.01803          0          9       1920: 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.56it/s]\n",
            "                   all         70        108      0.549       0.44      0.431      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19      13.3G    0.05517    0.01658          0          9       1920: 100% 6/6 [00:04<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.54it/s]\n",
            "                   all         70        108       0.65      0.574      0.539      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19      13.3G     0.0453    0.01843          0         16       1920: 100% 6/6 [00:04<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.53it/s]\n",
            "                   all         70        108      0.404      0.593      0.385       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19      13.3G    0.05261    0.01758          0          9       1920: 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.55it/s]\n",
            "                   all         70        108      0.631      0.574      0.567      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/19      13.3G    0.04695    0.01741          0          8       1920: 100% 6/6 [00:04<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.61it/s]\n",
            "                   all         70        108      0.653      0.626      0.569      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/19      13.3G    0.04625    0.01869          0         12       1920: 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.50it/s]\n",
            "                   all         70        108      0.653      0.626      0.569      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/19      13.3G    0.04172    0.01328          0          3       1920: 100% 6/6 [00:04<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.54it/s]\n",
            "                   all         70        108      0.737      0.596      0.586      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/19      13.3G    0.04255    0.01705          0          7       1920: 100% 6/6 [00:04<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.45it/s]\n",
            "                   all         70        108      0.757       0.62      0.622      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/19      13.3G    0.04456    0.01655          0          8       1920: 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.48it/s]\n",
            "                   all         70        108      0.728      0.602      0.592      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/19      13.3G    0.04227    0.01549          0          5       1920: 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.24it/s]\n",
            "                   all         70        108      0.728      0.602      0.592      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/19      13.3G    0.04197    0.01661          0          5       1920: 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.48it/s]\n",
            "                   all         70        108      0.687      0.593      0.557      0.184\n",
            "\n",
            "20 epochs completed in 0.036 hours.\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 15.3MB\n",
            "Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test on own dataset\n",
        "!python detect.py --source '/content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized' --weights /content/yolov5/runs/train/exp3/weights/last.pt --img 1440 --save-txt --save-conf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L733Bd-FiWvQ",
        "outputId": "a2131254-cb97-4ecc-8275-ba99c9d7bb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp3/weights/last.pt'], source=/content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized, data=data/coco128.yaml, imgsz=[1440, 1440], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v6.2-224-g82a5585 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/01334X2.jpg: 1088x1440 1 number_plate, 34.9ms\n",
            "image 2/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/075TST.jpg: 1088x1440 (no detections), 34.7ms\n",
            "image 3/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/102M091.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 4/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/115RZF.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 5/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/148NMM.jpg: 1088x1440 (no detections), 38.0ms\n",
            "image 6/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/151618AV.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 7/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1754ZG.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 8/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/17870.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 9/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/193CKR.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 10/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/198PA1.jpg: 1088x1440 (no detections), 26.5ms\n",
            "image 11/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/19EP68.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 12/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/19FE15.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 13/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1ACD17.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 14/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1EH133.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 15/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1EXL62.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 16/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1MA625.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 17/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1NWW19.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 18/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1TACH1.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 19/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/1VES425.jpg: 1088x1440 (no detections), 26.5ms\n",
            "image 20/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/215557W.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 21/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2178PZ.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 22/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2192285.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 23/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/223420AV.jpg: 1088x1440 (no detections), 26.5ms\n",
            "image 24/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2341546.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 25/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/236BBKW.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 26/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2A00315.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 27/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2A0164T.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 28/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2A01D46.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 29/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2A0BAN8.jpg: 1088x1440 1 number_plate, 26.0ms\n",
            "image 30/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2BJ6555.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 31/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2CA2573.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 32/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2CTS17.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 33/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2CW7888.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 34/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2XHZ78.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 35/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2XNX509.jpg: 1088x1440 (no detections), 26.2ms\n",
            "image 36/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/2YRC45.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 37/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/3091IF.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 38/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/3200978B.jpg: 1088x1440 (no detections), 26.2ms\n",
            "image 39/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/360Y7.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 40/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/3AXY37.jpg: 1088x1440 2 number_plates, 26.1ms\n",
            "image 41/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/3CL1702.jpg: 1088x1440 (no detections), 26.2ms\n",
            "image 42/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/3GX448.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 43/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/3HB922.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 44/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/3PHH499.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 45/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/402VWX.jpg: 1088x1440 (no detections), 26.3ms\n",
            "image 46/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/409RSC.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 47/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4167.jpg: 1088x1440 (no detections), 26.0ms\n",
            "image 48/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4528NQ.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 49/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4576PJ.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 50/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/45821M1.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 51/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4629864.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 52/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4685BH5.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 53/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/46BIZI.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 54/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/46BKTR.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 55/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/474626C.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 56/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/47849R2.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 57/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/491.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 58/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4ADMAN.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 59/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4ATR867.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 60/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4FPD800.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 61/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4JDF997.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 62/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4V20.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 63/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/4WES842.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 64/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5015596.jpg: 1088x1440 (no detections), 26.3ms\n",
            "image 65/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5016.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 66/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5043189.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 67/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/50516U2.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 68/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5059J.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 69/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5269QD.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 70/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/527CRC.jpg: 1088x1440 1 number_plate, 26.9ms\n",
            "image 71/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/528LYO.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 72/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5301SL.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 73/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/561MOY.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 74/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/568CMW.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 75/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/58011CH.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 76/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5AF1326.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 77/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5CE8316.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 78/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5DTT149.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 79/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5J2AF.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 80/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5PPH341.jpg: 1088x1440 (no detections), 26.2ms\n",
            "image 81/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5RCJ617.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 82/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5RCY584.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 83/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5T30T6.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 84/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/5T81125.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 85/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/632.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 86/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/64WWI.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 87/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/65207.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 88/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/653CUG.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 89/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/65876U1.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 90/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/66880.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 91/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/678JZX.jpg: 1088x1440 (no detections), 26.0ms\n",
            "image 92/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/693FM5.jpg: 1088x1440 (no detections), 26.0ms\n",
            "image 93/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6C3143.jpg: 1088x1440 (no detections), 26.0ms\n",
            "image 94/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6CW2676.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 95/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6DZF743.jpg: 1088x1440 (no detections), 27.2ms\n",
            "image 96/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6EEV644.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 97/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6MNE460.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 98/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6MZ612.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 99/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6RCB772.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 100/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6ROB436.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 101/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6SSE758.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 102/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6VQV257.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 103/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6VWC002.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 104/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6WBY955.jpg: 1088x1440 (no detections), 26.8ms\n",
            "image 105/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6WGX134.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 106/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/6ZVK926.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 107/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/73309E2.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 108/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7373XT.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 109/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/737WWW.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 110/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/75372.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 111/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/762589B.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 112/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/777272B.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 113/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7BV1583.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 114/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7BZ2298.jpg: 1088x1440 (no detections), 26.3ms\n",
            "image 115/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7CHN739.jpg: 1088x1440 (no detections), 26.5ms\n",
            "image 116/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7DP48.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 117/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7FKG273.jpg: 1088x1440 (no detections), 26.9ms\n",
            "image 118/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7GFB000.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 119/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7HAK197.jpg: 1088x1440 2 number_plates, 26.4ms\n",
            "image 120/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7HZM532.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 121/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7JTZ567.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 122/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7KLF928.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 123/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7NDF616.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 124/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7SMZ675.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 125/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7UOV181.jpg: 1088x1440 (no detections), 26.2ms\n",
            "image 126/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7VAW194.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 127/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7XAC334.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 128/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/7YWL235.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 129/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8077MD.jpg: 1088x1440 (no detections), 26.2ms\n",
            "image 130/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/827ZAW.jpg: 1088x1440 1 number_plate, 26.2ms\n",
            "image 131/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/828791.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 132/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8301068.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 133/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8392.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 134/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/841WJK.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 135/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/862FAL.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 136/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8706666.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 137/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8847ZG.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 138/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8BQK414.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 139/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8CS4462.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 140/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8CTJ018.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 141/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8DXJ582.jpg: 1088x1440 (no detections), 26.2ms\n",
            "image 142/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8FCT240.jpg: 1088x1440 (no detections), 26.6ms\n",
            "image 143/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8FJZ512.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 144/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8FYJ320.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 145/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8G24778.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 146/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8GMD934.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 147/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8HHH706.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 148/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8HJC724.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 149/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8HXC508.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 150/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8JAX261.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 151/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8KAU494.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 152/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8LKZ266.jpg: 1088x1440 1 number_plate, 27.7ms\n",
            "image 153/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8MJN918.jpg: 1088x1440 (no detections), 27.7ms\n",
            "image 154/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8NHF768.jpg: 1088x1440 1 number_plate, 27.7ms\n",
            "image 155/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8NUL101.jpg: 1088x1440 1 number_plate, 27.0ms\n",
            "image 156/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8RHE386.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 157/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8RKT663.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 158/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8RPL060.jpg: 1088x1440 (no detections), 27.1ms\n",
            "image 159/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8RUG646.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 160/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8RUW514.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 161/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8SPU355.jpg: 1088x1440 (no detections), 27.1ms\n",
            "image 162/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8TJW787.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 163/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8TVU222.jpg: 1088x1440 (no detections), 27.2ms\n",
            "image 164/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8UHW147.jpg: 1088x1440 1 number_plate, 27.0ms\n",
            "image 165/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8UQP774.jpg: 1088x1440 (no detections), 27.1ms\n",
            "image 166/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8VAJ352.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 167/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8VGV466.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 168/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8WDB049.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 169/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8YPT976.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 170/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8Z49N9.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 171/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8ZC.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 172/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/8ZRM109.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 173/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/9002.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 174/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/936TFJ.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 175/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/944EOH.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 176/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/962BBLH.jpg: 1088x1440 2 number_plates, 26.4ms\n",
            "image 177/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/9AOH137.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 178/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/9CS4792.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 179/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/A007K.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 180/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AD17805.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 181/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ADB372.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 182/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AEH6109.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 183/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AH63366.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 184/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AHD8242.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 185/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AJU6470.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 186/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AJX9319.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 187/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AK95019.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 188/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AKT7545.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 189/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ANKLMAN.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 190/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ANU5797.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 191/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/APV9135.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 192/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ARRL74.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 193/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AS16372.jpg: 1088x1440 (no detections), 26.9ms\n",
            "image 194/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AS55555.jpg: 1088x1440 (no detections), 28.1ms\n",
            "image 195/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AV39622.jpg: 1088x1440 (no detections), 28.0ms\n",
            "image 196/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AW75879.jpg: 1088x1440 (no detections), 28.5ms\n",
            "image 197/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/AY33613.jpg: 1088x1440 (no detections), 28.5ms\n",
            "image 198/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/B2844.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 199/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BAW7934.jpg: 1088x1440 (no detections), 28.9ms\n",
            "image 200/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BAZ264.jpg: 1088x1440 (no detections), 28.9ms\n",
            "image 201/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BBE8843.jpg: 1088x1440 (no detections), 28.1ms\n",
            "image 202/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BBL9385.jpg: 1088x1440 (no detections), 28.1ms\n",
            "image 203/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BC28555.jpg: 1088x1440 (no detections), 28.1ms\n",
            "image 204/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BC64874.jpg: 1088x1440 (no detections), 28.1ms\n",
            "image 205/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BG33032.jpg: 1088x1440 (no detections), 28.0ms\n",
            "image 206/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BM72376.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 207/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BN36137.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 208/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BU16401.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 209/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BU31415.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 210/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BURAK29.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 211/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BWZ0734.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 212/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BX21195.jpg: 1088x1440 1 number_plate, 28.1ms\n",
            "image 213/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BX68782.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 214/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/BX97822.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 215/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/C2G679.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 216/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CA15632.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 217/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CC28558.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 218/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CCG.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 219/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CD30224.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 220/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CE72993.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 221/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CEKA1.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 222/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CF42516.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 223/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CF42812.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 224/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CF99815.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 225/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CG48864.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 226/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CG95664.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 227/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CGF267.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 228/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CH90046.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 229/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CHEVERE.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 230/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CK68578.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 231/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CL57789.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 232/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CLERK1.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 233/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CM80414.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 234/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CMJ.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 235/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CN73122.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 236/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CN80775.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 237/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/COOWHP.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 238/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CQ48365.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 239/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CQ78487.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 240/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CQ79779.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 241/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CR59110.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 242/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CRASH2.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 243/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CS35804.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 244/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CTCHUP.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 245/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/CXDM35.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 246/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/D18NAX.jpg: 1088x1440 (no detections), 26.5ms\n",
            "image 247/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DBJ686.jpg: 1088x1440 (no detections), 26.4ms\n",
            "image 248/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DEAL777.jpg: 1088x1440 1 number_plate, 26.5ms\n",
            "image 249/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DELIA.jpg: 1088x1440 (no detections), 26.5ms\n",
            "image 250/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DEMNWRX.jpg: 1088x1440 1 number_plate, 26.4ms\n",
            "image 251/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DEV1712.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 252/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DM26019.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 253/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DNAWS.jpg: 1088x1440 (no detections), 26.0ms\n",
            "image 254/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DRDONNA.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 255/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DS11251.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 256/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DSC1980.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 257/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/DYT244.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 258/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/E932262.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 259/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/EBTLUVR.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 260/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/EJK4046.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 261/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ELV9702.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 262/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/EMMYG.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 263/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ER183.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 264/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/EV4207.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 265/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/EVPQ53.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 266/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/FLC832.jpg: 1088x1440 1 number_plate, 26.1ms\n",
            "image 267/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/FN3155.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 268/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/FT9704.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 269/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/FV1693.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 270/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/FVC6245.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 271/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/FX5665.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 272/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/FYR6206.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 273/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/G69AUX.jpg: 1088x1440 (no detections), 26.1ms\n",
            "image 274/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/GC6C9W.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 275/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/GRIESRS.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 276/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/GRTSCT.jpg: 1088x1440 (no detections), 26.9ms\n",
            "image 277/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/GXB777.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 278/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/H442302.jpg: 1088x1440 (no detections), 27.1ms\n",
            "image 279/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HEYDER5.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 280/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HKY221.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 281/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HNK3143.jpg: 1088x1440 (no detections), 27.1ms\n",
            "image 282/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HPF561.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 283/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HPYBUG.jpg: 1088x1440 (no detections), 27.5ms\n",
            "image 284/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HTC895.jpg: 1088x1440 1 number_plate, 27.7ms\n",
            "image 285/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HUJ245.jpg: 1088x1440 5 number_plates, 27.7ms\n",
            "image 286/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HWD850.jpg: 1088x1440 (no detections), 28.0ms\n",
            "image 287/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HWT777.jpg: 1088x1440 (no detections), 28.0ms\n",
            "image 288/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/HYE683.jpg: 1088x1440 (no detections), 28.2ms\n",
            "image 289/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/IC71SC.jpg: 1088x1440 (no detections), 27.5ms\n",
            "image 290/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/IIBL13.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 291/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/IJPD05.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 292/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/IMKRUZN.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 293/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JAL5778.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 294/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JAM1364.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 295/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JDQ430.jpg: 1088x1440 1 number_plate, 27.4ms\n",
            "image 296/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JENNSON.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 297/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JIMBUG.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 298/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JMN9670.jpg: 1088x1440 (no detections), 27.5ms\n",
            "image 299/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JPA7344.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 300/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JT41.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 301/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JTS4581.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 302/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/JZK5213.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 303/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/KDE799.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 304/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/KDM282.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 305/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/KEX806.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 306/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/KGM6888.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 307/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/KVC4390.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 308/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/KWT5342.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 309/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/L154467.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 310/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/L464522.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 311/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/L6LMI.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 312/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LAG9442.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 313/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LC36.jpg: 1088x1440 (no detections), 26.8ms\n",
            "image 314/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LEB4439.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 315/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LEP725.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 316/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LHT9443.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 317/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LKB9906.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 318/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LKH4849.jpg: 1088x1440 (no detections), 26.6ms\n",
            "image 319/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LLB0602.jpg: 1088x1440 1 number_plate, 26.7ms\n",
            "image 320/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LOUDV10.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 321/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LRJ9524.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 322/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LSZRX7.jpg: 1088x1440 (no detections), 26.8ms\n",
            "image 323/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LUIS93.jpg: 1088x1440 1 number_plate, 26.7ms\n",
            "image 324/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/LUVSHEL.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 325/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/M7161V.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 326/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/MAGIERA.jpg: 1088x1440 1 number_plate, 26.7ms\n",
            "image 327/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/MBB4244.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 328/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/MBDNA.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 329/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/MFM3.jpg: 1088x1440 (no detections), 26.8ms\n",
            "image 330/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/MOTO533.jpg: 1088x1440 (no detections), 28.0ms\n",
            "image 331/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/MPWRS55.jpg: 1088x1440 (no detections), 28.1ms\n",
            "image 332/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/N44AYM.jpg: 1088x1440 1 number_plate, 28.8ms\n",
            "image 333/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/NAV957.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 334/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/NCYDREW.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 335/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/NHBEAR.jpg: 1088x1440 (no detections), 27.1ms\n",
            "image 336/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/NHY4688.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 337/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/NORTH.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 338/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/NOTFAKE.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 339/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/NSMRT.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 340/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/P208754.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 341/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PASHA.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 342/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PBP728.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 343/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PEKET.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 344/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PMF2472.jpg: 1088x1440 1 number_plate, 27.0ms\n",
            "image 345/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PMW5000.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 346/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PND2100.jpg: 1088x1440 1 number_plate, 27.0ms\n",
            "image 347/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PRIMUSO.jpg: 1088x1440 (no detections), 27.1ms\n",
            "image 348/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PTU174.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 349/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/PVI107.jpg: 1088x1440 1 number_plate, 27.0ms\n",
            "image 350/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/Q361832.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 351/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/Q555218.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 352/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/QBK676.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 353/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/QJU533.jpg: 1088x1440 1 number_plate, 27.0ms\n",
            "image 354/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/QJY818.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 355/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/QWIKGTOAV.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 356/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/R35GDZA.jpg: 1088x1440 (no detections), 27.0ms\n",
            "image 357/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/R49RCW.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 358/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RCM1663.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 359/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RFD.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 360/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RIM3552.jpg: 1088x1440 1 number_plate, 28.8ms\n",
            "image 361/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RKR175.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 362/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RLQ328.jpg: 1088x1440 (no detections), 28.5ms\n",
            "image 363/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RMN022.jpg: 1088x1440 1 number_plate, 28.5ms\n",
            "image 364/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ROAST.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 365/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RQJ740.jpg: 1088x1440 1 number_plate, 28.4ms\n",
            "image 366/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RSE802.jpg: 1088x1440 1 number_plate, 28.4ms\n",
            "image 367/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RT5419.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 368/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RUB103.jpg: 1088x1440 1 number_plate, 27.3ms\n",
            "image 369/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RWJ0248.jpg: 1088x1440 1 number_plate, 27.3ms\n",
            "image 370/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RWZ3436.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 371/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RYE147.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 372/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/RZG260.jpg: 1088x1440 (no detections), 26.8ms\n",
            "image 373/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/S295953.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 374/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/S9.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 375/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SCARPY.jpg: 1088x1440 1 number_plate, 27.0ms\n",
            "image 376/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SCF1853.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 377/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SDD8942.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 378/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SEA2SKY.jpg: 1088x1440 2 number_plates, 26.7ms\n",
            "image 379/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SFB842.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 380/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SKNDRYA.jpg: 1088x1440 2 number_plates, 26.6ms\n",
            "image 381/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SUY476.jpg: 1088x1440 1 number_plate, 26.7ms\n",
            "image 382/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SWB.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 383/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/SZACUN.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 384/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TANNY64.jpg: 1088x1440 1 number_plate, 26.7ms\n",
            "image 385/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TAROT.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 386/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TAYA9.jpg: 1088x1440 1 number_plate, 26.8ms\n",
            "image 387/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TCI6335.jpg: 1088x1440 2 number_plates, 26.7ms\n",
            "image 388/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TCM2690.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 389/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TDL6006.jpg: 1088x1440 1 number_plate, 26.7ms\n",
            "image 390/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/THEKING.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 391/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TROMBONE.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 392/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TTP281.jpg: 1088x1440 (no detections), 26.7ms\n",
            "image 393/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TUL605.jpg: 1088x1440 1 number_plate, 26.7ms\n",
            "image 394/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/TUMMILO.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 395/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/U754AO.jpg: 1088x1440 1 number_plate, 27.5ms\n",
            "image 396/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/UCV475.jpg: 1088x1440 (no detections), 27.6ms\n",
            "image 397/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/UHHHWUT.jpg: 1088x1440 (no detections), 27.7ms\n",
            "image 398/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/UKK2622.jpg: 1088x1440 (no detections), 27.9ms\n",
            "image 399/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/UMADES.jpg: 1088x1440 (no detections), 28.1ms\n",
            "image 400/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/URNEXTT.jpg: 1088x1440 2 number_plates, 28.0ms\n",
            "image 401/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/UTK894.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 402/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/UTV0LZ.jpg: 1088x1440 (no detections), 28.5ms\n",
            "image 403/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/UZZ5686.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 404/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/V821C.jpg: 1088x1440 1 number_plate, 28.5ms\n",
            "image 405/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VDZ3146.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 406/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VFP1336.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 407/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VHD588.jpg: 1088x1440 (no detections), 28.5ms\n",
            "image 408/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VHE706.jpg: 1088x1440 1 number_plate, 28.4ms\n",
            "image 409/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VIZZY.jpg: 1088x1440 (no detections), 28.4ms\n",
            "image 410/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VLY610.jpg: 1088x1440 (no detections), 28.5ms\n",
            "image 411/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VMH4947.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 412/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VMX5223.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 413/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VNA260.jpg: 1088x1440 (no detections), 29.1ms\n",
            "image 414/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VSS5703.jpg: 1088x1440 1 number_plate, 29.3ms\n",
            "image 415/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VTD4298.jpg: 1088x1440 1 number_plate, 29.2ms\n",
            "image 416/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VUI159.jpg: 1088x1440 1 number_plate, 28.8ms\n",
            "image 417/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VVN1676.jpg: 1088x1440 (no detections), 28.9ms\n",
            "image 418/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VVY9259.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 419/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VWU8934.jpg: 1088x1440 (no detections), 28.8ms\n",
            "image 420/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VXB9675.jpg: 1088x1440 1 number_plate, 28.8ms\n",
            "image 421/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VXH8897.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 422/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/VZY1324.jpg: 1088x1440 (no detections), 27.3ms\n",
            "image 423/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/WYK3294.jpg: 1088x1440 1 number_plate, 27.3ms\n",
            "image 424/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/XE8N6J.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 425/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/Y58GBH.jpg: 1088x1440 1 number_plate, 27.5ms\n",
            "image 426/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/Z322250.jpg: 1088x1440 1 number_plate, 27.4ms\n",
            "image 427/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/Z517639.jpg: 1088x1440 (no detections), 27.5ms\n",
            "image 428/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ZTB7147.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 429/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ZW.jpg: 1088x1440 (no detections), 27.4ms\n",
            "image 430/430 /content/drive/MyDrive/ML-AI Project/Data/Data_2_Resized/ZZ97697.jpg: 1088x1440 (no detections), 27.3ms\n",
            "Speed: 1.6ms pre-process, 26.9ms inference, 0.5ms NMS per image at shape (1, 3, 1440, 1440)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n",
            "77 labels saved to runs/detect/exp3/labels\n"
          ]
        }
      ]
    }
  ]
}